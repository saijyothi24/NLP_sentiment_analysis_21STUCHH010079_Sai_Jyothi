{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8b46SWUvuGx"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk spacy gensim pandas scikit-learn\n",
        "#pip: A package manager for Python that allows you to install and manage software packages written in Python.\n",
        "#install: A command used with pip to download and install the specified packages from the Python Package Index (PyPI) or other repositories.\n",
        "#nltk: Stands for Natural Language Toolkit, a library used for working with human language data (text). It provides easy-to-use interfaces and resources for tasks like tokenization, parsing, and classification.\n",
        "#spacy: An open-source library for advanced Natural Language Processing (NLP) in Python. It is designed for performance and includes features like tokenization, part-of-speech tagging, and named entity recognition.\n",
        "#gensim: A Python library for topic modeling and document similarity analysis, primarily used for processing and analyzing large text corpora.\n",
        "#pandas: A powerful data manipulation and analysis library for Python, providing data structures like DataFrames for handling structured data.\n",
        "#scikit-learn: A machine learning library for Python that provides simple and efficient tools for data mining and data analysis, including classification, regression, clustering, and dimensionality reduction."
      ],
      "metadata": {
        "id": "Osoh-IpZwuYp",
        "outputId": "f3b09eea-cb81-4309-eb59-bee77a20fb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ3M5cCUN6i8"
      },
      "source": [
        "##Introduction\n",
        "Jupyter notebooks is an open-source web-based Python editor which runs in your browser. It allows a combination of text written in a html-like format known as \"markdown\", such as the block of text you're reading right now, and inline code, tools and outputs such as this one:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Download the Punkt tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = \"Hello, world! This is NLP.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)\n",
        "#import: A statement used to include modules or specific functions from a module into your Python program, allowing you to use the features defined in those modules.\n",
        "#from: A keyword used in conjunction with import to specify the exact module or part of a module you want to import. In this case, it suggests importing from a specific submodule.\n",
        "#tokenize: Refers to a submodule or package named tokenize that is part of the current package (denoted by the dot). It likely contains functions for breaking text into tokens.\n",
        "#sentence: A variable that stores a string containing a sentence. In this case, it is \"Hello, world! This is NLP.\"\n",
        "#tokens: A variable that stores the result of the tokenization process, which is the output of the word_tokenize function applied to the sentence.\n",
        "#word_tokenize: A function (presumably from the tokenize module) that takes a string as input and splits it into individual tokens (words and punctuation).\n",
        "#print: A built-in Python function that outputs the specified message or variable value to the console.\n",
        "#Output: A comment that describes the expected output of the preceding line of code. In this case, it shows what the tokens variable will contain after tokenization.\n",
        "#['Hello', ',', 'world', '!', 'This', 'is', 'NLP', '.']: A list of tokens resulting from the tokenization of the input sentence. Each word and punctuation mark is treated as a separate token."
      ],
      "metadata": {
        "id": "BqtrcvM2xL5h",
        "outputId": "3aa9ee3a-c602-4543-d5dc-c291f79ac0fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'This', 'is', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Download the Punkt tokenizer\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "AmQQ5MkGxMQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in\n",
        "stop_words]\n",
        "print(filtered_tokens)\n",
        "#corpus: A term often used to refer to a large collection of texts used for linguistic research, though in this context it seems to be part of the import statement.\n",
        "#stopwords: A module or submodule (likely from the NLTK library) that provides a list of common words (like \"the,\" \"is,\" \"in\") that are usually filtered out in text processing because they carry less meaning.\n",
        "#download: A method from the NLTK library that retrieves and installs specified resources (like stopword lists) for use in your NLP tasks.\n",
        "#stop_words: A variable that stores a set of English stopwords, which are words that are typically ignored in natural language processing tasks.\n",
        "#set: A built-in Python data type that represents an unordered collection of unique elements. Here, it’s used to store stopwords for efficient membership testing.\n",
        "#filtered_tokens: A variable that stores a list of tokens after filtering out the stopwords.\n",
        "#tokens: A list variable (from the previous snippet) that contains the tokenized words and punctuation from the original sentence.\n",
        "#word: A variable used in the list comprehension to represent each individual token as it is processed.\n",
        "#word.lower(): A method that converts a string to lowercase, allowing for case-insensitive comparison.\n",
        "#not in: A membership operator that checks if a specified element is not present in a collection (in this case, checking if the token is not a stopword).\n",
        "#print: A built-in Python function that outputs the specified message or variable value to the console."
      ],
      "metadata": {
        "id": "AYwn_9rSxMTx",
        "outputId": "5f00ab3b-a6ec-4e77-8681-9dd84c866bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'NLP', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "ps = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(ps.stem(\"faster\")) # Output: run\n",
        "print(lemmatizer.lemmatize(\"faster\")) # Output: running (more context needed for lemmatization)\n",
        "#stem: This is likely a part of the import statement for the PorterStemmer class from the NLTK library, which is used for stemming words.\n",
        "#PorterStemmer: A class from the NLTK library that implements the Porter stemming algorithm, which reduces words to their base or root for#m (e.g., \"running\" becomes \"run\").\n",
        "#nltk.stem: A submodule in the NLTK library that provides classes and functions for stemming and lemmatization.\n",
        "#WordNetLemmatizer: A class in the NLTK library that uses the WordNet lexical database to perform lemmatization, which is the process of reducing a word to its base form based on its meaning (e.g., \"better\" becomes \"good\").\n",
        "#nltk.download('wordnet'): A method that downloads the WordNet lexical database, which is required for the WordNetLemmatizer to function properly.\n",
        "#ps: A variable that is an instance of the PorterStemmer class, allowing access to its stemming methods.\n",
        "#lemmatizer: A variable that is an instance of the WordNetLemmatizer class, allowing access to its lemmatization methods.\n",
        "#print: A built-in Python function that outputs the specified message or variable value to the console.\n",
        "#ps.stem(\"faster\"): A method call that applies the stemming process to the word \"faster,\" returning its stemmed form. This will likely output \"faster\" or \"fast\" depending on the implementation.\n"
      ],
      "metadata": {
        "id": "z-jisxs7xMWw",
        "outputId": "25832466-57cd-46fc-dd47-19203ff1ce20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faster\n",
            "faster\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics.\n",
        "#pandas as pd: An import statement that includes the pandas library and gives it the alias pd. Pandas is used for data manipulation and analysis.\n",
        "#nltk: The Natural Language Toolkit, a library for working with human language data, though it's included here without any specific functions being imported.\n",
        "#from: A keyword used in conjunction with import to specify the exact module or part of a module you want to import.\n",
        "#sklearn.model_selection: A submodule of scikit-learn that provides functions for splitting datasets into training and testing sets.\n",
        "#train_test_split: A function from the model_selection submodule that splits arrays or matrices into random train and test subsets, useful for evaluating machine learning models.\n",
        "#sklearn.feature_extraction.text: A submodule of scikit-learn that includes tools for converting text data into numerical features.\n",
        "#CountVectorizer: A class from the feature_extraction.text submodule that converts a collection of text documents to a matrix of token counts, representing how many times each word appears.\n",
        "#sklearn.naive_bayes: A submodule of scikit-learn that implements Naive Bayes classifiers for various types of data.\n",
        "#MultinomialNB: A class from the naive_bayes submodule that implements the Multinomial Naive Bayes algorithm, commonly used for classification tasks with discrete features (like word counts).\n",
        "#sklearn: Short for scikit-learn, a machine learning library in Python that provides simple and efficient tools for data mining and data analysis.\n",
        "#metrics: A submodule of scikit-learn that provides functions for evaluating the performance of machine learning models, such as accuracy, precision, recall, and F1-score.\n"
      ],
      "metadata": {
        "id": "V8_SafrRxMZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        " 'text': [\n",
        " 'I love this movie!',\n",
        " 'This was a terrible movie.',\n",
        " 'I really enjoyed the film.',\n",
        " 'Worst experience ever.',\n",
        " 'It was fantastic!',\n",
        " 'Not worth the time.',\n",
        " 'Absolutely amazing!',\n",
        " 'It was okay, not great.',\n",
        " 'I hate this film.',\n",
        " 'Best movie ever!'\n",
        " ],\n",
        " 'sentiment': [\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'neutral',\n",
        " 'negative',\n",
        " 'positive'\n",
        " ]\n",
        "}"
      ],
      "metadata": {
        "id": "9R-6RevNxMca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "#df: A variable that typically stands for \"DataFrame,\" which is a two-dimensional, size-mutable, potentially heterogeneous tabular data structure in pandas.\n",
        "#pd: The alias for the pandas library, allowing access to its functions and classes. It was defined in the earlier import statement (import pandas as pd).\n",
        "#DataFrame: A class in the pandas library that represents a table of data, similar to a spreadsheet or SQL table. It allows for storing data in rows and columns with labeled axes.\n",
        "#data: A variable (not explicitly defined in this snippet) that is expected to contain the data to be converted into a DataFrame. This could be in various forms, such as a dictionary, list of lists, or a NumPy array"
      ],
      "metadata": {
        "id": "Y5-e8Mtf7WT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "WuzprVcA2za-",
        "outputId": "449ff830-3615-4185-f61f-ff2e3170814e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         text sentiment\n",
            "0          I love this movie!  negative\n",
            "1  This was a terrible movie.  positive\n",
            "2  I really enjoyed the film.  negative\n",
            "3      Worst experience ever.  positive\n",
            "4           It was fantastic!  negative\n",
            "5         Not worth the time.  positive\n",
            "6         Absolutely amazing!  negative\n",
            "7     It was okay, not great.   neutral\n",
            "8           I hate this film.  negative\n",
            "9            Best movie ever!  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "# Vectorize the text\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "#X: A variable that typically represents the feature set (input data) in a machine learning context. In this case, it is set to the 'text' column of the DataFrame df.\n",
        "#y: A variable that typically represents the target variable (output data) in a machine learning context. Here, it is set to the 'sentiment' column of the DataFrame df.\n",
        "#X_train, X_test, y_train, y_test: Variables that hold the training and testing datasets after splitting. X_train and y_train are for training, while X_test and y_test are for testing the model.\n",
        "#train_test_split: A function that splits the dataset into training and testing subsets. It takes the input features (X), the target variable (y), the proportion of the data to be used for testing (test_size), and a random state for reproducibility.\n",
        "#test_size=0.2: A parameter in the train_test_split function that specifies that 20% of the data should be allocated to the test set, while the remaining 80% will be used for training.\n",
        "#random_state=42: A parameter that sets the seed for the random number generator, ensuring that the split is reproducible across different runs.\n",
        "#vectorizer: A variable that holds an instance of the CountVectorizer class, which is used to convert text data into a numerical format.\n",
        "#CountVectorizer(): A class from scikit-learn that converts a collection of text documents to a matrix of token counts.\n",
        "#X_train_vectorized: A variable that stores the vectorized representation of the training text data (X_train), created by fitting and transforming the CountVectorizer.\n",
        "#X_test_vectorized: A variable that stores the vectorized representation of the testing text data (X_test), created by transforming the data using the previously fitted vectorizer.\n",
        "#fit_transform: A method of the CountVectorizer that learns the vocabulary from the training data and transforms it into a document-term matrix.\n",
        "#transform: A method of the CountVectorizer that transforms new data into the document-term matrix using the vocabulary learned from the training data.\n"
      ],
      "metadata": {
        "id": "xl3rcshl2zeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "#model: A variable that holds an instance of a machine learning model. In this case, it represents the Naive Bayes classifier.\n",
        "#MultinomialNB(): A class from the naive_bayes module in scikit-learn that implements the Multinomial Naive Bayes algorithm, commonly used for classification tasks involving discrete features, like word counts.\n",
        "#model.fit(): A method that trains the model using the training data. It takes the feature set (X_train_vectorized) and the target variable (y_train) as inputs.\n",
        "#X_train_vectorized: The matrix of token counts for the training data, which was created using the CountVectorizer earlier. This serves as the input for training the model.\n",
        "#y_train: The target variable for the training set, representing the sentiment labels corresponding to the training data.\n"
      ],
      "metadata": {
        "id": "3WfuP5iV2zhb",
        "outputId": "8887c679-d55a-4647-a00c-709bda4e6838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_vectorized)\n",
        "#y_pred: A variable that stores the predicted values generated by the model for the test dataset. It represents the model's output (predicted sentiments) based on the input features.\n",
        "#model.predict(): A method used to make predictions based on the input features. It takes the vectorized test data (X_test_vectorized) as input and returns the predicted labels.\n",
        "#X_test_vectorized: The matrix of token counts for the test data, created using the CountVectorizer. This serves as the input for making predictions with the trained model."
      ],
      "metadata": {
        "id": "3Iei5_lB2zkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix)\n",
        "#accuracy: A variable that stores the accuracy of the model, which is a measure of how often the model's predictions match the actual labels in the test dataset.\n",
        "#metrics: A submodule of scikit-learn that provides functions for evaluating the performance of machine learning models.\n",
        "#accuracy_score(): A function from the metrics module that calculates the accuracy of predictions by comparing the true labels (y_test) with the predicted labels (y_pred).\n",
        "#confusion_matrix: A variable that stores the confusion matrix, which is a table used to evaluate the performance of a classification model. It shows the number of true positive, true negative, false positive, and false negative predictions.\n",
        "#confusion_matrix(): A function from the metrics module that computes the confusion matrix based on the true labels (y_test) and predicted labels (y_pred).\n",
        "#print(): A built-in Python function used to output messages or variable values to the console.\n",
        "#f'Accuracy: {accuracy:.2f}': An f-string (formatted string) that formats the accuracy value to two decimal places for display in the output.\n",
        "#'Confusion Matrix:': A string that serves as a label for the confusion matrix output.\n"
      ],
      "metadata": {
        "id": "C97Mu6N92znB",
        "outputId": "baad2791-8c2c-44ff-9a05-b8bed33e536e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n",
            "Confusion Matrix:\n",
            "[[0 2]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        " text_vectorized = vectorizer.transform([text])\n",
        " prediction = model.predict(text_vectorized)\n",
        " return prediction[0]\n",
        "# Example usage\n",
        "new_text = \"I loved the plot and the acting!\"\n",
        "print(f'Sentiment: {predict_sentiment(new_text)}')\n",
        "#def: A keyword used to define a new function in Python.\n",
        "#predict_sentiment: The name of the function being defined. It takes a single argument, text, which represents the input text whose sentiment needs to be predicted.\n",
        "#text: A parameter of the function that represents the input string for which sentiment prediction is to be made.\n",
        "#text_vectorized: A variable that stores the vectorized representation of the input text. This is done by transforming the text using the previously fitted CountVectorizer.\n",
        "#vectorizer.transform(): A method that transforms the input text into a document-term matrix using the vocabulary learned from the training data.\n",
        "#model.predict(): A method that predicts the sentiment based on the vectorized input text. It returns the predicted sentiment label.\n",
        "#prediction: A variable that stores the result of the prediction, which is typically an array of predicted sentiment labels.\n",
        "#return: A statement that exits the function and sends back the specified value to the caller.\n",
        "#prediction[0]: Accesses the first element of the prediction array, which represents the predicted sentiment label.\n",
        "#new_text: A variable that stores a new input string, in this case, \"I loved the plot and the acting!\", for which the sentiment will be predicted.\n",
        "#print(): A built-in Python function used to output messages or variable values to the console.\n",
        "#f'Sentiment: {predict_sentiment(new_text)}': An f-string that calls the predict_sentiment function with new_text as an argument and formats the output string to display the predicted sentiment.\n"
      ],
      "metadata": {
        "id": "R2BKZbFq2zpc",
        "outputId": "b8b6c1fd-88b1-4668-968a-186023165329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFG_BTei2zry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpuvM0MkxMiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHI0ogXbvuGy"
      },
      "source": [
        "print(\"Hello World\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvjJu5iNvuG1"
      },
      "source": [
        "This combination allows for the procution of beautiful documents containing software, documentation and discussion. For larger codes you may wish to use Python in a stand-alone environment such as a traditional IDE. But for demonstration purposes Jupyter is a very useful tool.\n",
        "\n",
        "Notebook files have the extension \".ipynb\" extension. A Jupyter notebook is one of many environments you may run Python code.  Colab and the Jupyter notebook editor in Anaconda are two of the many pieces of software you may use to write and run a Jupyter notebook. For this course we recommend using the online Google Colab tool, but you can use Anaconda to run the notebooks on your own machine within an internet connection. On college computers, Jupyter can be used by launchng Anaconda from the Software Hub Apps Anywhere interface.\n",
        "\n",
        "Note that exact interfaces will differ between different environments but the same functionality should be found in most environments. This course will be using the Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4ThcjVNBfb"
      },
      "source": [
        "## Cells and Executing Code\n",
        "\n",
        "A notebooks is made up of one or more \"cells\". Cells can contain the html-like text used to generate text or code to be run by the user. A cell containing a piece of code may be recognised by the the  ```[]```  to the left of it. Code in these blocks can be run in a nubmer of ways. The simplest is click on the ```[ ]``` . This will execute the code. Try this with the code snippet below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znQZKSLZvuG2"
      },
      "source": [
        "print(\"Yes, it worked!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX2A7djDvuG4"
      },
      "source": [
        "You should have seen the message \"Yes, it worked!\" appear immediately beneath the code. This is the output of the code, which has been printed to the screen. You may also have noticed a number appear between the square brackets to the left of the code snippet. This indicates the order in which the code snippet has been executed. Code cells may be executed in any order and variables will be saved between execution of code snippets. To try this, execute the three codes snippets below in the following order:\n",
        "- 1\n",
        "- 2\n",
        "- 3\n",
        "- 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAE233GJvuG4"
      },
      "source": [
        "a=\"Message 1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt9NlZYyvuG6"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZUIOI-ZvuG8"
      },
      "source": [
        "a=\"Message 2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCXAZCPzNUWr"
      },
      "source": [
        "The first time you ran code snippet 1 you should have seen \"Message 1\" as the output and the second time the output should have been \"Message 2\". This is because the first time it was run, the value assigned to the variable named \"a\" was \"Message\" as set by the first code snippet and the second time it was \"Message 2\" as set by the third code snippet. Note also the current numbers contained within square brackets. These help you to kno which cells have been executed and in which order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8YYhdP7NbjD"
      },
      "source": [
        "##Sharing Jupyter Notebooks on Colab\n",
        "When a Jupyter Notebook is shared with you on Colab, you will often receive access to the notebook which will alow you to run code, but not edit it. This should be the case for the notebooks that form part of this course. In this case you can select \"Save a Copy in Drive\" from the \"File\" menu to create a new copy that is yours and yo can edit.\n",
        "\n",
        "For this course, it is reccommended that you create two copies. One of these should be the original copy without your edits, and another which you can edit to compelte exercises or expierment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSpv_w2nvuG-"
      },
      "source": [
        "## Basic Jupyter Commands\n",
        "\n",
        "Jupyter contains a number of useful tools for executing these cells. By using the \"Runtime\" menu, you can run multiple cells at a time using \"Run all\", \"Run before\", \"Run selected\" and \"Run after\".\n",
        "\n",
        "You can clear output (this is the term for what is written under a code cell when it's executed) by clicking on the symbol to the left of it. You can clear all outputs from the notebook using the \"Clear All Outputs\" command on the \"Edit\" menu. Clearing the output will not unset variables set by the code snippets run, only remove the output printed to the screen.\n",
        "\n",
        "To unset variables, use the \"Restart Runtime\" or \"Reset Runtime\" option in the Runtime menu. The \"Interrupt Execution\" command on the kernel menu will halt the procesing of code, which can be useful if you've accidentally written a piece of code that will never finish executing or if the code is taking too long to execute.\n",
        "\n",
        "The \"insert\" menu allows you to create new cells. The \"cell type\" option in the \"cell\" menu allows you toggle the current cell type between the different cell types available:\n",
        "- **Code**: Code snippets\n",
        "- **Text**: The html-like language used to generate text, tables, equations, etc.\n",
        "\n",
        "Alternatively, you can hover your mouse in the space after a cell and add a code or text cell there.\n",
        "\n",
        "###Exercise\n",
        "\n",
        "Try each of these commands from the different menus for yourself on this  notebook and ensure they behave as you would expect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY8lQr8RNgnL"
      },
      "source": [
        "## Text Cells in Jupyter\n",
        "You can include all sort so information in Jupyter text cells to obtain different effects. To see how each of the following examples is generated, double click on this cell. To return to the formatted text, run the cell.\n",
        "\n",
        "### Headings\n",
        "Headings can be generated using the hash symbol \"#\". The more of these there are, the smaller the heading. The sub-sub-heading above is an example.\n",
        "\n",
        "### Tables\n",
        "Tables can be created in a way similar to basic html, using the a comabination of the \"|\" and \"-\" symbols:\n",
        "\n",
        "| This | is    |\n",
        "|------|-------|\n",
        "|   a  |  table|\n",
        "| It's | fancy |\n",
        "\n",
        "### Equations\n",
        "Equations can be written in a way similar to LaTeX by surrouding the text with \"\\$\" symbols:\n",
        "\n",
        "$a=\\frac{\\int\\limits_{0}^{\\pi} \\sin{(bx)} \\textrm{d}x}{4}$\n",
        "\n",
        "Don't worry if you don't understand the exact syntax used to generate this example. In your example of it in your exercise, try writing something very simple instead. If it looks like a simple algebraic expression, it will probably render how you intend.\n",
        "\n",
        "### Code Snippets\n",
        "You can write snippets of code in a text cell and they will be highlighted as if they were code written in a code cell. This can be useful for demonstrating a code feature in a textual way. For example:\n",
        "\n",
        "```python\n",
        "print (\"Hello World\")\n",
        "```\n",
        "\n",
        "There is not a way to run this code, it is merely normal text highlighted to look like code. The \"python\" which precedes the code itself tells Jupyter which language you are writing the code snippet in so it can be highlighted accorindly.\n",
        "\n",
        "In some environments, text cells may also be referred to as \"markdown\" cells.\n",
        "\n",
        "###Exercise\n",
        "Try creating simple versions of each of the constructs above in a new text cell below this one."
      ]
    }
  ]
}